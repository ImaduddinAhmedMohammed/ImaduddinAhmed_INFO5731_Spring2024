{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ImaduddinAhmedMohammed/ImaduddinAhmed_INFO5731_Spring2024/blob/main/Mohammed_Imad_5731_Exercise_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdRwkJBn70nX"
      },
      "source": [
        "# **INFO5731 In-class Exercise 5**\n",
        "\n",
        "**This exercise aims to provide a comprehensive learning experience in text analysis and machine learning techniques, focusing on both text classification and clustering tasks.**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Please use the text corpus you collected in your last in-class-exercise for this exercise. Perform the following tasks***.\n",
        "\n",
        "**Expectations**:\n",
        "*   Students are expected to complete the exercise during lecture period to meet the active participation criteria of the course.\n",
        "*   Use the provided .*ipynb* document to write your code & respond to the questions. Avoid generating a new file.\n",
        "*   Write complete answers and run all the cells before submission.\n",
        "*   Make sure the submission is \"clean\"; *i.e.*, no unnecessary code cells.\n",
        "*   Once finished, allow shared rights from top right corner (*see Canvas for details*).\n",
        "\n",
        "**Total points**: 40\n",
        "\n",
        "**Deadline**: This in-class exercise is due at the end of the day tomorrow, at 11:59 PM.\n",
        "\n",
        "**Late submissions will have a penalty of 10% of the marks for each day of late submission, and no requests will be answered. Manage your time accordingly.**\n"
      ],
      "metadata": {
        "id": "TU-pLW33lpcS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARqm7u6B70ne"
      },
      "source": [
        "## **Question 1 (20 Points)**\n",
        "\n",
        "The purpose of the question is to practice different machine learning algorithms for **text classification** as well as the performance evaluation. In addition, you are requried to conduct **10 fold cross validation** (https://scikit-learn.org/stable/modules/cross_validation.html) in the training.\n",
        "\n",
        "\n",
        "\n",
        "The dataset can be download from canvas. The dataset contains two files train data and test data for sentiment analysis in IMDB review, it has two categories: 1 represents positive and 0 represents negative. You need to split the training data into training and validate data (80% for training and 20% for validation, https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6) and perform 10 fold cross validation while training the classifier. The final trained model was final evaluated on the test data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Algorithms:**\n",
        "\n",
        "*   MultinominalNB\n",
        "*   SVM\n",
        "*   KNN\n",
        "*   Decision tree\n",
        "*   Random Forest\n",
        "*   XGBoost\n",
        "*   Word2Vec\n",
        "*   BERT\n",
        "\n",
        "**Evaluation measurement:**\n",
        "\n",
        "\n",
        "*   Accuracy\n",
        "*   Recall\n",
        "*   Precison\n",
        "*   F-1 score\n"
      ],
      "metadata": {
        "id": "loi8Sh7UE6ha"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "VAZj4PHB70nf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "8b04b68c-3c68-4fea-a157-54b28f2079d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-732bf6eca74b>:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  train_data = pd.read_csv('stsa-train.txt',sep = 'delimiter=',header= None,names=['text'])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text sentiment\n",
              "0  a stirring , funny and finally transporting re...         1\n",
              "1  apparently reassembled from the cutting-room f...         0\n",
              "2  they presume their audience wo n't sit still f...         0\n",
              "3  this is a visually stunning rumination on love...         1\n",
              "4  jonathan parker 's bartleby should have been t...         1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dae55e8a-df73-4847-84b3-809ff298c951\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a stirring , funny and finally transporting re...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>apparently reassembled from the cutting-room f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>they presume their audience wo n't sit still f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>this is a visually stunning rumination on love...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>jonathan parker 's bartleby should have been t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dae55e8a-df73-4847-84b3-809ff298c951')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dae55e8a-df73-4847-84b3-809ff298c951 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dae55e8a-df73-4847-84b3-809ff298c951');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3ac0a6ec-d391-453a-9bc9-533fbef2bce0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3ac0a6ec-d391-453a-9bc9-533fbef2bce0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3ac0a6ec-d391-453a-9bc9-533fbef2bce0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_data",
              "summary": "{\n  \"name\": \"train_data\",\n  \"rows\": 6920,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6911,\n        \"samples\": [\n          \"a loud , brash and mainly unfunny high school comedy .\",\n          \"the real star of this movie is the score , as in the songs translate well to film , and it 's really well directed .\",\n          \"rosenthal -lrb- halloween ii -rrb- seems to have forgotten everything he ever knew about generating suspense .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"0\",\n          \"1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Write your code here\n",
        "import pandas as pd\n",
        "train_data = pd.read_csv('stsa-train.txt',sep = 'delimiter=',header= None,names=['text'])\n",
        "train_data[['sentiment', 'text']] = train_data['text'].str.split(\" \", n=1, expand=True)\n",
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = pd.read_csv('stsa-test.txt',sep = 'delimiter=',header= None,names=['text'])\n",
        "test_data[['sentiment','text']] = test_data['text'].str.split(\" \", n=1, expand=True)\n",
        "test_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "hSldWuRw8txK",
        "outputId": "879d249d-c6ac-4ea9-a36d-4c833b7a21bf"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-948ab59e9dc1>:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  test_data = pd.read_csv('stsa-test.txt',sep = 'delimiter=',header= None,names=['text'])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text sentiment\n",
              "0     no movement , no yuks , not much of anything .         0\n",
              "1  a gob of drivel so sickly sweet , even the eag...         0\n",
              "2  gangs of new york is an unapologetic mess , wh...         0\n",
              "3  we never really feel involved with the story ,...         0\n",
              "4            this is one of polanski 's best films .         1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2a5639ae-5e2e-4301-8c0e-55a83bf4f1a8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>no movement , no yuks , not much of anything .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a gob of drivel so sickly sweet , even the eag...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gangs of new york is an unapologetic mess , wh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>we never really feel involved with the story ,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>this is one of polanski 's best films .</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2a5639ae-5e2e-4301-8c0e-55a83bf4f1a8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2a5639ae-5e2e-4301-8c0e-55a83bf4f1a8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2a5639ae-5e2e-4301-8c0e-55a83bf4f1a8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1642da95-515d-4a19-b406-49754fb4f199\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1642da95-515d-4a19-b406-49754fb4f199')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1642da95-515d-4a19-b406-49754fb4f199 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_data",
              "summary": "{\n  \"name\": \"test_data\",\n  \"rows\": 1821,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1821,\n        \"samples\": [\n          \"there is no entry portal in the rules of attraction , and i spent most of the movie feeling depressed by the shallow , selfish , greedy characters .\",\n          \"a charming yet poignant tale of the irrevocable ties that bind .\",\n          \"it 's all pretty cynical and condescending , too .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"1\",\n          \"0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "import string\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "stopword=nltk.corpus.stopwords.words('english')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wl= WordNetLemmatizer()\n",
        "\n",
        "def clean(review):\n",
        "    review =\"\".join([word.lower() for word in review if word not in string.punctuation])\n",
        "    review = re.sub(\"^\\d+\\s|\\s\\d+\\s|\\s\\d+$\", \" \", review)\n",
        "    tokens = re.split('\\W+',review)\n",
        "    review = [wl.lemmatize(word) for word in tokens if word not in stopword]\n",
        "    return review"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bz3hiOsT6E0-",
        "outputId": "cb60492a-2cbb-45cd-9c31-f3b80558370d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf_vect = TfidfVectorizer(analyzer = clean)\n",
        "X_tfidf = tfidf_vect.fit_transform(train_data['text'])\n",
        "\n",
        "print(X_tfidf.shape)\n",
        "\n",
        "\n",
        "\n",
        "X_tfidf_df=pd.DataFrame(X_tfidf.toarray())\n",
        "X_tfidf_df.columns = tfidf_vect.get_feature_names_out()\n",
        "X_test_tfidf = tfidf_vect.transform(test_data['text'])\n",
        "print(X_test_tfidf.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngnskNV_75sh",
        "outputId": "7c6216b6-0146-41b2-b454-79d9fa3b917e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6920, 13343)\n",
            "(1821, 13343)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MultinomialNB\n",
        "from sklearn import datasets, linear_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "mnb = MultinomialNB()\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_tfidf_df, train_data['sentiment'].values,\n",
        "                                                test_size=0.2, random_state=42)\n",
        "\n",
        "model_mnb = mnb.fit(x_train,y_train)\n",
        "y_pred_mnb = model_mnb.predict(x_test)\n",
        "print('Accuracy %s' % accuracy_score(y_pred_mnb,y_test))\n",
        "print(classification_report(y_test,y_pred_mnb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPm4Ks7t9OO4",
        "outputId": "b57b954f-4042-4dc2-9f60-a1bf8b372a3e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.7955202312138728\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.70      0.77       671\n",
            "           1       0.76      0.88      0.82       713\n",
            "\n",
            "    accuracy                           0.80      1384\n",
            "   macro avg       0.80      0.79      0.79      1384\n",
            "weighted avg       0.80      0.80      0.79      1384\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(mnb, x_test, y_test, cv=10)\n",
        "print(\"MultinominalNB score: \",scores.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bSBjZZ39jAO",
        "outputId": "92637a11-386e-41ec-f293-d353f3bd6e3e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MultinominalNB score:  0.7247054530288813\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, cross_validate, StratifiedKFold\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "svm = LinearSVC()\n",
        "model_svm = svm.fit(x_train,y_train)\n",
        "y_pred_svm = model_svm.predict(x_test)\n",
        "print('Accuracy %s' % accuracy_score(y_pred_svm,y_test))\n",
        "print(classification_report(y_test,y_pred_svm))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSjIo7669sEW",
        "outputId": "6b320755-e508-4c2c-9104-2f0b55cb792a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.791907514450867\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.75      0.78       671\n",
            "           1       0.78      0.83      0.80       713\n",
            "\n",
            "    accuracy                           0.79      1384\n",
            "   macro avg       0.79      0.79      0.79      1384\n",
            "weighted avg       0.79      0.79      0.79      1384\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = cross_val_score(svm, x_test, y_test, cv=10)\n",
        "print(\"SVM score:\",scores.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExcqHy_N9zBu",
        "outputId": "dbe4b3a0-fb45-44b0-dd96-f434c33fa542"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM score: 0.7348034615785632\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# KNN\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=5,n_jobs=-1)\n",
        "model_knn = knn.fit(x_train,y_train)\n",
        "y_pred_knn = model_knn.predict(x_test)\n",
        "print('Accuracy %s' % accuracy_score(y_pred_knn,y_test))\n",
        "print(classification_report(y_test,y_pred_knn))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-af21s593Zc",
        "outputId": "64a168d2-f34b-48ee-87f5-29c217fdb231"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.740606936416185\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.71      0.73       671\n",
            "           1       0.74      0.77      0.75       713\n",
            "\n",
            "    accuracy                           0.74      1384\n",
            "   macro avg       0.74      0.74      0.74      1384\n",
            "weighted avg       0.74      0.74      0.74      1384\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = cross_val_score(knn, x_test, y_test, cv=10)\n",
        "print(\"KNN score:\",scores.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eDCUkIN-CVU",
        "outputId": "7a6e4688-ca22-4692-ccd6-9d6bf1b18616"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN score: 0.6675737670732979\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision Tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "dt = DecisionTreeClassifier()\n",
        "model_dt = dt.fit(x_train,y_train)\n",
        "y_pred_dt = model_dt.predict(x_test)\n",
        "print('Accuracy %s' % accuracy_score(y_pred_dt,y_test))\n",
        "print(classification_report(y_test,y_pred_dt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_6yU2Ui-Dpf",
        "outputId": "0d447ae6-4153-4d3d-bd85-6d9e7bccc0f2"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.6524566473988439\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.62      0.63       671\n",
            "           1       0.66      0.68      0.67       713\n",
            "\n",
            "    accuracy                           0.65      1384\n",
            "   macro avg       0.65      0.65      0.65      1384\n",
            "weighted avg       0.65      0.65      0.65      1384\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = cross_val_score(dt, x_test, y_test, cv=10)\n",
        "print(\"Decision tree score:\",scores.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqfpuKIz-Hbv",
        "outputId": "2bdedaff-19ea-4503-fc00-2e7d6c3edceb"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision tree score: 0.6098060681889271\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier()\n",
        "model_rf = rf.fit(x_train,y_train)\n",
        "y_pred_rf = model_rf.predict(x_test)\n",
        "print('Accuracy %s' % accuracy_score(y_pred_rf,y_test))\n",
        "print(classification_report(y_test,y_pred_rf))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saNy4c5_-REk",
        "outputId": "c7378b54-3546-4938-b065-feac64652cb8"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.7333815028901735\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.64      0.70       671\n",
            "           1       0.71      0.82      0.76       713\n",
            "\n",
            "    accuracy                           0.73      1384\n",
            "   macro avg       0.74      0.73      0.73      1384\n",
            "weighted avg       0.74      0.73      0.73      1384\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = cross_val_score(rf, x_test, y_test, cv=10)\n",
        "print(\"Random forest score\",scores.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUK1Pz41-ViY",
        "outputId": "204c24c6-ef10-41c6-9f00-8610750d276f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random forest score 0.6711656761547284\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# XGBoost\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "y_train = y_train.astype(int)\n",
        "y_test = y_test.astype(int)\n",
        "\n",
        "xgboost_model = XGBClassifier()\n",
        "model_xgb = xgboost_model.fit(x_train, y_train)\n",
        "\n",
        "y_pred_xgb = model_xgb.predict(x_test)\n",
        "\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred_xgb))\n",
        "print(classification_report(y_test, y_pred_xgb))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQt_iV-P-a1a",
        "outputId": "233727dc-69fb-4c02-c23d-072976046efb"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7189306358381503\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.60      0.67       671\n",
            "           1       0.69      0.83      0.75       713\n",
            "\n",
            "    accuracy                           0.72      1384\n",
            "   macro avg       0.73      0.72      0.71      1384\n",
            "weighted avg       0.73      0.72      0.71      1384\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = cross_val_score(xgboost_model, x_test, y_test, cv=10)\n",
        "print(\"XGBoost score:\",scores.mean())"
      ],
      "metadata": {
        "id": "GjyhPlsq-h-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "id": "eDsQYvNs-i6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "train_tokens = [clean(text) for text in train_data['text']]\n",
        "w2v_model = Word2Vec(sentences=train_tokens, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "def document_vector(doc):\n",
        "    doc = [word for word in doc if word in w2v_model.wv.key_to_index]\n",
        "    return np.mean(w2v_model.wv[doc], axis=0) if doc else np.zeros(w2v_model.vector_size)\n",
        "\n",
        "X_train_w2v = np.array([document_vector(doc) for doc in train_tokens])\n",
        "train_data['sentiment'] = train_data['sentiment'].astype(int)\n",
        "y_train = train_data['sentiment'].values\n",
        "\n",
        "classifier = LogisticRegression()\n",
        "cv_results_w2v = cross_validate(classifier, X_train_w2v, y_train, cv=10, scoring=['accuracy', 'precision', 'recall', 'f1'])\n",
        "\n",
        "print(\"Word2Vec Cross-Validation Results:\")\n",
        "print(\"Accuracy: \", np.mean(cv_results_w2v['test_accuracy']))\n",
        "print(\"Precision: \", np.mean(cv_results_w2v['test_precision']))\n",
        "print(\"Recall: \", np.mean(cv_results_w2v['test_recall']))\n",
        "print(\"F1 Score: \", np.mean(cv_results_w2v['test_f1']))\n"
      ],
      "metadata": {
        "id": "omWil2H5BH0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = cross_val_score(classifier, x_test, y_test, cv=10)\n",
        "print(\"Word 2 Vec Score:\",scores.mean())"
      ],
      "metadata": {
        "id": "uK3g8sPiGt3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch"
      ],
      "metadata": {
        "id": "xckx_EtvI-DO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_validate\n",
        "import numpy as np\n",
        "\n",
        "# Initialize BERT tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "def bert_embedding(text):\n",
        "    \"\"\"Generate BERT embeddings for a given text.\"\"\"\n",
        "    encoded_input = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        output = model(**encoded_input)\n",
        "    # Use the output of the [CLS] token (first token) for document classification\n",
        "    return output.last_hidden_state[:, 0, :].numpy().squeeze()\n",
        "\n",
        "# Obtain BERT embeddings for each document in the dataset\n",
        "X_train_bert = np.array([bert_embedding(text) for text in train_data['text']])\n",
        "\n",
        "# Logistic Regression model\n",
        "log_reg = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Perform 10-fold cross-validation\n",
        "cv_results_bert = cross_validate(log_reg, X_train_bert, train_data['sentiment'].values, cv=10, scoring=['accuracy', 'precision_macro', 'recall_macro', 'f1_macro'])\n",
        "print(\"BERT Cross-Validation Results:\")\n",
        "print(\"Accuracy: \", np.mean(cv_results_bert['test_accuracy']))\n",
        "print(\"Precision: \", np.mean(cv_results_bert['test_precision_macro']))\n",
        "print(\"Recall: \", np.mean(cv_results_bert['test_recall_macro']))\n",
        "print(\"F1 Score: \", np.mean(cv_results_bert['test_f1_macro']))\n"
      ],
      "metadata": {
        "id": "J7jdacpNJJk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEUjBE6C70nf"
      },
      "source": [
        "## **Question 2 (20 Points)**\n",
        "\n",
        "The purpose of the question is to practice different machine learning algorithms for **text clustering**.\n",
        "\n",
        "Please downlad the dataset by using the following link.  https://www.kaggle.com/PromptCloudHQ/amazon-reviews-unlocked-mobile-phones\n",
        "(You can also use different text data which you want)\n",
        "\n",
        "**Apply the listed clustering methods to the dataset:**\n",
        "*   K-means\n",
        "*   DBSCAN\n",
        "*   Hierarchical clustering\n",
        "*   Word2Vec\n",
        "*   BERT\n",
        "\n",
        "You can refer to of the codes from  the follwing link below.\n",
        "https://www.kaggle.com/karthik3890/text-clustering"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
        "from gensim.models import Word2Vec\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import numpy as np\n",
        "import torch\n",
        "from collections import Counter\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('Amazon_Unlocked_Mobile.csv')\n",
        "df = df.dropna(subset=['Reviews'])\n",
        "\n",
        "# Preprocess the text data\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "X = vectorizer.fit_transform(df['Reviews'])\n",
        "\n",
        "# K-Means Clustering\n",
        "kmeans = KMeans(n_clusters=5, random_state=42)\n",
        "labels_kmeans = kmeans.fit_predict(X)\n",
        "print(\"K-Means Clustering:\")\n",
        "for i in range(5):\n",
        "    cluster_index = np.where(labels_kmeans == i)\n",
        "    sample_reviews = df.iloc[cluster_index]['Reviews'].sample(2, random_state=42).tolist()\n",
        "    print(f\"Cluster {i} examples: {sample_reviews}\")\n",
        "\n",
        "# DBSCAN Clustering\n",
        "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
        "labels_dbscan = dbscan.fit_predict(X)\n",
        "n_clusters_dbscan = len(set(labels_dbscan)) - (1 if -1 in labels_dbscan else 0)\n",
        "print(\"\\nDBSCAN Clustering:\")\n",
        "print(f\"Number of clusters: {n_clusters_dbscan}\")\n",
        "if n_clusters_dbscan > 1:\n",
        "    for label in set(labels_dbscan):\n",
        "        if label != -1:\n",
        "            cluster_index = np.where(labels_dbscan == label)\n",
        "            sample_reviews = df.iloc[cluster_index]['Reviews'].sample(1, random_state=42).tolist()\n",
        "            print(f\"Cluster {label} example: {sample_reviews}\")\n",
        "\n",
        "# Hierarchical Clustering\n",
        "agg = AgglomerativeClustering(n_clusters=5)\n",
        "labels_agg = agg.fit_predict(X.toarray())\n",
        "print(\"\\nHierarchical Clustering:\")\n",
        "for i in range(5):\n",
        "    cluster_index = np.where(labels_agg == i)\n",
        "    sample_reviews = df.iloc[cluster_index]['Reviews'].sample(2, random_state=42).tolist()\n",
        "    print(f\"Cluster {i} examples: {sample_reviews}\")\n",
        "\n",
        "# Word2Vec Clustering\n",
        "sentences = df['Reviews'].apply(lambda x: x.split()).tolist()\n",
        "w2v_model = Word2Vec(sentences, vector_size=100, window=5, min_count=5, workers=4)\n",
        "word_vectors = w2v_model.wv.vectors\n",
        "kmeans_w2v = KMeans(n_clusters=5, random_state=42)\n",
        "labels_w2v = kmeans_w2v.fit_predict(word_vectors)\n",
        "print(\"\\nWord2Vec Clustering:\")\n",
        "top_words = []\n",
        "for i in range(5):\n",
        "    cluster_index = np.where(labels_w2v == i)\n",
        "    words = [w2v_model.wv.index_to_key[idx] for idx in cluster_index[0]]\n",
        "    most_common = Counter(words).most_common(5)\n",
        "    top_words.append(most_common)\n",
        "    print(f\"Cluster {i} most common words: {most_common}\")\n",
        "\n",
        "# BERT Clustering\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "bert_embeddings = []\n",
        "\n",
        "for review in df['Reviews']:\n",
        "    inputs = tokenizer(review, return_tensors='pt', truncation=True, max_length=128)\n",
        "    outputs = model(**inputs)\n",
        "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
        "    bert_embeddings.append(embeddings.detach().numpy().squeeze())\n",
        "\n",
        "bert_embeddings = np.array(bert_embeddings)\n",
        "kmeans_bert = KMeans(n_clusters=5, random_state=42)\n",
        "labels_bert = kmeans_bert.fit_predict(bert_embeddings)\n",
        "print(\"\\nBERT Clustering:\")\n",
        "for i in range(5):\n",
        "    cluster_index = np.where(labels_bert == i)\n",
        "    sample_reviews = df.iloc[cluster_index]['Reviews'].sample(2, random_state=42).tolist()\n",
        "    print(f\"Cluster {i} examples: {sample_reviews}\")\n"
      ],
      "metadata": {
        "id": "lr_zLni_V34c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "YOfWdNDoujrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews= reviews[reviews['Reviews'].notnull()].head(5000)\n",
        "\n",
        "reviews['punctuation'] = reviews['Reviews'].str.replace('[^\\w\\s].#','')#eliminatng punctuatiions\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "stop = stopwords.words('english')\n",
        "reviews['stopwords'] =reviews['punctuation'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))#eliminatng stopwords\n",
        "reviews['numerics']=reviews['stopwords'].str.replace('[0-9]','')#eliminatng numercis\n",
        "reviews['lowercase'] =reviews['numerics'].apply(lambda x: \" \".join(x.lower() for x in x.split()))#to lowercase\n",
        "from nltk.stem import PorterStemmer# for Stemming\n",
        "stemmer = PorterStemmer()\n",
        "reviews['stemming']=reviews['lowercase'].apply(lambda x: \" \".join([stemmer.stem(word) for word in x.split()]))\n",
        "#Lemmatizing\n",
        "from textblob import Word\n",
        "reviews['cleaned_data'] = reviews['stemming'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
        "reviews['cleaned_data']"
      ],
      "metadata": {
        "id": "g4doqUkHuppc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "\n",
        "vector = TfidfVectorizer()\n",
        "tfidf = vector.fit_transform(reviews['cleaned_data'].values)\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "kmodel = KMeans(n_clusters = 5,random_state=99) #Defining k means model\n",
        "kmodel.fit(tfidf)\n",
        "labels_kmeans = kmodel.labels_ #Creating labels\n",
        "cluster_center_kmeans=kmodel.cluster_centers_ #Defining tcluster center\n",
        "terms = vector.get_feature_names_out()\n",
        "terms[1:10]\n",
        "reviews['Label'] = kmodel.labels_\n",
        "reviews"
      ],
      "metadata": {
        "id": "x8FcouZbuv8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Finding top terms\n",
        "print(\"Top terms:\")\n",
        "#Defing the centroid model\n",
        "centroids = kmodel.cluster_centers_.argsort()[:, ::-1]\n",
        "#Creating the loop for finding the top words\n",
        "for i in range(5):\n",
        "    print(\"Cluster %d:\" % i, end='')\n",
        "    for ind in centroids[i, :5]:\n",
        "        print(' %s' % terms[ind], end='')\n",
        "        print()"
      ],
      "metadata": {
        "id": "J7Pl5m7pu11t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "import numpy as np\n",
        "\n",
        "points = 2 * 100\n",
        "def lower_b(nums, targ):\n",
        "    l, r = 0, len(nums) - 1\n",
        "    while l <= r:\n",
        "        mid = int(l + (r - l) / 2)\n",
        "        if nums[mid] >= targ:\n",
        "            r = mid - 1\n",
        "        else:\n",
        "            l = mid + 1\n",
        "    return l\n",
        "def com_200th_near_tneigh(x, data):\n",
        "    dists = []\n",
        "    for val in data:\n",
        "        dist = np.sum((x - val) **2 )\n",
        "        if(len(dists) == 200 and dists[199] > dist):\n",
        "            l = int(lower_b(dists, dist))\n",
        "            if l < 200 and l >= 0 and dists[l] > dist:\n",
        "                dists[l] = dist\n",
        "            else:\n",
        "              dists.append(dist)\n",
        "              dists.sort()\n",
        "\n",
        "    return dists[199]\n",
        "import numpy as np\n",
        "sent_vectors = [];\n",
        "for sent in reviews['Reviews']:\n",
        "    sent_vec = np.zeros(100)\n",
        "    words =0;\n",
        "    for word in sent:\n",
        "        try:\n",
        "            vec = tfidf.wv[word]\n",
        "            sent_vec += vec\n",
        "            words += 1\n",
        "        except:\n",
        "            pass\n",
        "    sent_vec /= words\n",
        "    sent_vectors.append(sent_vec)\n",
        "sent_vectors = np.array(sent_vectors)\n",
        "sent_vectors = np.nan_to_num(sent_vectors)\n",
        "sent_vectors.shape\n",
        "points = 2 * 100\n",
        "model = DBSCAN(eps = 1, min_samples = points, n_jobs=-1)\n",
        "model.fit(sent_vectors)\n",
        "reviews['AVG Cluster Label'] = model.labels_\n",
        "reviews"
      ],
      "metadata": {
        "id": "uuYnfE9vu8fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "    print(\"5 reviews of ensured to cluster \", i)\n",
        "    print(\"-\" * 70)\n",
        "    print(reviews.iloc[reviews.groupby(['Label']).groups[i][0]]['cleaned_data'])\n",
        "    print('\\n')\n",
        "    print(reviews.iloc[reviews.groupby(['Label']).groups[i][5]]['cleaned_data'])\n",
        "    print('\\n')\n",
        "    print(\"_\" * 70)"
      ],
      "metadata": {
        "id": "o0fte84du-3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import AgglomerativeClustering\n",
        "#Defining model\n",
        "cluster = AgglomerativeClustering(n_clusters=10, affinity='euclidean', linkage='ward')\n",
        "Agg=cluster.fit_predict(sent_vectors)\n",
        "#assigning Labels\n",
        "aggdf = reviews\n",
        "aggdf['AVG Cluster Label'] = cluster.labels_\n",
        "aggdf.head()"
      ],
      "metadata": {
        "id": "KGb-PE3PvB-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aggdf.groupby(['Label'])['cleaned_data'].count()"
      ],
      "metadata": {
        "id": "2bJUinocvICD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for index in range(5):\n",
        "    print(\"Review\", index)\n",
        "    print(\"-\" * 100)\n",
        "    print(aggdf.iloc[aggdf.groupby(['Label']).groups[index][0]]['cleaned_data'])\n",
        "    print('\\n')\n",
        "    print(aggdf.iloc[aggdf.groupby(['Label']).groups[index][1]]['cleaned_data'])\n",
        "    print('\\n')\n",
        "    print(\"_\" * 100)"
      ],
      "metadata": {
        "id": "5EwWVP02vIv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "\n",
        "# Create a list of cleaned reviews\n",
        "cleaned_reviews = reviews['cleaned_data'].tolist()\n",
        "\n",
        "# Train a Word2Vec model\n",
        "model = gensim.models.Word2Vec(cleaned_reviews, size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Extract the embeddings for the reviews\n",
        "review_vectors = []\n",
        "for review in cleaned_reviews:\n",
        "    vector = np.zeros(100)\n",
        "    words = review.split()\n",
        "    for i, word in enumerate(words):\n",
        "        if word in model.wv.vocab:\n",
        "            vector += model.wv[word]\n",
        "    vector /= len(words)\n",
        "    review_vectors.append(vector)\n",
        "\n",
        "# Convert the list of vectors to a NumPy array\n",
        "review_vectors = np.array(review_vectors)\n"
      ],
      "metadata": {
        "id": "oN45tNuEvh5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "# Load the BERT tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Extract the embeddings for the reviews\n",
        "review_vectors = []\n",
        "for review in cleaned_reviews:\n",
        "    inputs = tokenizer(review, return_tensors='pt')\n",
        "    outputs = model(**inputs)\n",
        "    vector = outputs.last_hidden_state[:, 0, :]\n",
        "    review_vectors.append(vector.detach().numpy())\n",
        "\n",
        "# Convert the list of vectors to a NumPy array\n",
        "review_vectors = np.array(review_vectors)\n"
      ],
      "metadata": {
        "id": "tlushCNaw4tw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In one paragraph, please compare the results of K-means, DBSCAN, Hierarchical clustering, Word2Vec, and BERT.**"
      ],
      "metadata": {
        "id": "tRijW2aLGONl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Write your response here:**\n",
        "The computation is taking too long for all the algorithms. K-Means shows some distinct clusters since the data set is large. DBScan is inaccurate because of large data set. Hierarchical clustering is good but the score is less than k-means. Word 2 vec is good.\n",
        "\n",
        ".\n",
        "\n",
        ".\n",
        "\n",
        ".\n",
        "\n",
        ".\n",
        "\n",
        ".\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pIYCj5qyGfSL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mandatory Question"
      ],
      "metadata": {
        "id": "VEs-OoDEhTW4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Important: Reflective Feedback on this exercise**\n",
        "\n",
        "Please provide your thoughts and feedback on the exercises you completed in this assignment.\n",
        "\n",
        "\n",
        "**(Your submission will not be graded if this question is left unanswered)**\n",
        "\n"
      ],
      "metadata": {
        "id": "IUKC7suYhVl0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "'''\n",
        "Please write you answer here:\n",
        "It takes time to write a code like this. For me personally, I have another class\n",
        "on thursday and almost very little time to complete the exercise. The compiling\n",
        "of the codes take a lot of time. Couldn't learn much while doing this but will\n",
        "look at it again after submitting it.\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "CAq0DZWAhU9m"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}